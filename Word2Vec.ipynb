{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from six.moves import urllib\n",
    "import tensorflow as tf\n",
    "import word2vec\n",
    "import re\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training using file /home/claire/Documents/jobs/job-hunting/massively/text8\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-244f64e5bfcb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# this might take a minute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvecfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/home/claire/Documents/jobs/job-hunting/massively/text8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mword2vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword2vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvecfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/home/claire/Documents/jobs/job-hunting/massively/text8.bin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword2vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/claire/Documents/jobs/job-hunting/massively/text8.bin'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/word2vec/scripts_interface.py\u001b[0m in \u001b[0;36mword2vec\u001b[0;34m(train, output, size, window, sample, hs, negative, threads, iter_, min_count, alpha, debug, binary, cbow, save_vocab, read_vocab, verbose)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mcommand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread_vocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mrun_cmd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/word2vec/scripts_interface.py\u001b[0m in \u001b[0;36mrun_cmd\u001b[0;34m(command, verbose)\u001b[0m\n\u001b[1;32m    142\u001b[0m                             stderr=subprocess.PIPE)\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m             \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ascii'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train word2vec with sample word list dataset\n",
    "# this might take a minute\n",
    "vecfile = '/home/claire/Documents/jobs/job-hunting/massively/text8'\n",
    "word2vec.word2vec(vecfile, '/home/claire/Documents/jobs/job-hunting/massively/text8.bin', size=100, verbose=True)\n",
    "model = word2vec.load('/home/claire/Documents/jobs/job-hunting/massively/text8.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the vector model\n",
    "model = word2vec.load('/home/claire/Documents/jobs/job-hunting/massively/text8.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_nfpu</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1956967666</th>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956967696</th>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956968487</th>\n",
       "      <td>I should be sleep, but im not! thinking about ...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956969035</th>\n",
       "      <td>@charviray Charlene my love. I miss you</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956969172</th>\n",
       "      <td>@kelcouch I'm sorry  at least it's Friday?</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956970047</th>\n",
       "      <td>Ugh! I have to beat this stupid song to get to...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956970424</th>\n",
       "      <td>@BrodyJenner if u watch the hills in london u ...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956971077</th>\n",
       "      <td>The storm is here and the electricity is gone</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956971206</th>\n",
       "      <td>So sleepy again and it's not even that late. I...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956971586</th>\n",
       "      <td>How are YOU convinced that I have always wante...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956972359</th>\n",
       "      <td>so tired and i think i'm definitely going to g...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956972557</th>\n",
       "      <td>@IsaacMascote  i'm sorry people are so rude to...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956973598</th>\n",
       "      <td>Fudge.... Just BS'd that whole paper.... So ti...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956976312</th>\n",
       "      <td>@ether_radio yeah :S i feel all funny cause i ...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956977084</th>\n",
       "      <td>mmm much better day... so far! it's still quit...</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956979150</th>\n",
       "      <td>I'm having a problem with my photo here in twi...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956982383</th>\n",
       "      <td>@maternitytees Aww  Onward and upwards now, ya...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956982576</th>\n",
       "      <td>diesel yaris... 70mpg  so sad its not availabl...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956982605</th>\n",
       "      <td>I want to buy this great album but unfortunate...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956983160</th>\n",
       "      <td>@Pokinatcha  in all honesty...pain   blech.</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956983171</th>\n",
       "      <td>Ok ... the passengers ... no one is alive ... ...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956983690</th>\n",
       "      <td>@vincew @stefanyngo  i fell asleep on the beac...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956983874</th>\n",
       "      <td>So great to see Oin &amp;amp; Cynthia.  So happy. ...</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956985535</th>\n",
       "      <td>@havingmysay  dude, that is my favorite sandwi...</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956985764</th>\n",
       "      <td>@RachelLock22 ohh thursday i have exams.. all ...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956986211</th>\n",
       "      <td>@gcrush @nopantsdance i was just thinking abou...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956986767</th>\n",
       "      <td>@artfuldodga I love those 'it'sakey' USB stick...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956989514</th>\n",
       "      <td>@sweeetnspicy hiii im on my ipod...i cant fall...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956989526</th>\n",
       "      <td>dont wanna work 11-830 tomorrow  but i get paid</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956989560</th>\n",
       "      <td>feels sad coz i wasnt able to play with the gu...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753903325</th>\n",
       "      <td>Had a great time last night!</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753903509</th>\n",
       "      <td>@watermelon39 haha! And Twitter! Hard though i...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753903552</th>\n",
       "      <td>@HosamKamel Thanks for the follow man</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753903798</th>\n",
       "      <td>@dai_bach daps were the best lol</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753903814</th>\n",
       "      <td>@DebbieFletcher haha i will remember that  xx</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753903881</th>\n",
       "      <td>@sharlynnx ME TOO! please come online *-* hope...</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753904142</th>\n",
       "      <td>@JamesHancox LOL or maybe it's the tooth fairy...</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753904185</th>\n",
       "      <td>Wow! Up, coffee in hand and already outside.  ...</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753904324</th>\n",
       "      <td>THE VIDEO IS FINALLY DONE WOOOOOOOOOOOOOOOOOOO...</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753904357</th>\n",
       "      <td>Watched Wolverine yesterday ... a spur of the ...</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753904398</th>\n",
       "      <td>is heading off to the fair</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753904399</th>\n",
       "      <td>the sunset view is SO beautiful from my room!</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753904448</th>\n",
       "      <td>@McMedia Very well thank you! How are you, mor...</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753904494</th>\n",
       "      <td>@muffinwomanxo EH! u dont like retro? tisk tis...</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753904626</th>\n",
       "      <td>@acchanosaurus good luck chan! gue kmrn bawa b...</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753904912</th>\n",
       "      <td>Sitting in Gatwick- going home for a week! can...</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753904919</th>\n",
       "      <td>@maynaseric good luck with your auction</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753905121</th>\n",
       "      <td>@McMedia husband is golfing &amp;amp; the Toddler ...</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753905153</th>\n",
       "      <td>going to watch boy in the striped pj's hope i ...</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753918809</th>\n",
       "      <td>gave the bikes a thorough wash, degrease it an...</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753918818</th>\n",
       "      <td>had SUCH and AMAZING time last night, McFly we...</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753918900</th>\n",
       "      <td>Succesfully following Tayla!!</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753919043</th>\n",
       "      <td>@niariley WASSUP BEAUTIFUL!!! FOLLOW ME!!  PEE...</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1965997032</th>\n",
       "      <td>Missing my baby ducks</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1694587827</th>\n",
       "      <td>Have just bought a TV tuner for my laptop.  He...</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1751358127</th>\n",
       "      <td>i now know that we've made a difference in eac...</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1695411449</th>\n",
       "      <td>@supermouse104 hey arthur! i forgot to say tha...</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1964096165</th>\n",
       "      <td>@neoknits -- That's got to be hard. My parents...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1961440619</th>\n",
       "      <td>@herecomesdomzi and what about me, huh? I'm cr...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1752415055</th>\n",
       "      <td>And ... Happy Mother's Day to all Moms   You s...</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10362 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     features      label\n",
       "id_nfpu                                                                 \n",
       "1956967666  Layin n bed with a headache  ughhhh...waitin o...    sadness\n",
       "1956967696               Funeral ceremony...gloomy friday...     sadness\n",
       "1956968487  I should be sleep, but im not! thinking about ...    sadness\n",
       "1956969035           @charviray Charlene my love. I miss you     sadness\n",
       "1956969172         @kelcouch I'm sorry  at least it's Friday?    sadness\n",
       "1956970047  Ugh! I have to beat this stupid song to get to...    sadness\n",
       "1956970424  @BrodyJenner if u watch the hills in london u ...    sadness\n",
       "1956971077     The storm is here and the electricity is gone     sadness\n",
       "1956971206  So sleepy again and it's not even that late. I...    sadness\n",
       "1956971586  How are YOU convinced that I have always wante...    sadness\n",
       "1956972359  so tired and i think i'm definitely going to g...    sadness\n",
       "1956972557  @IsaacMascote  i'm sorry people are so rude to...    sadness\n",
       "1956973598  Fudge.... Just BS'd that whole paper.... So ti...    sadness\n",
       "1956976312  @ether_radio yeah :S i feel all funny cause i ...    sadness\n",
       "1956977084  mmm much better day... so far! it's still quit...  happiness\n",
       "1956979150  I'm having a problem with my photo here in twi...    sadness\n",
       "1956982383  @maternitytees Aww  Onward and upwards now, ya...    sadness\n",
       "1956982576  diesel yaris... 70mpg  so sad its not availabl...    sadness\n",
       "1956982605  I want to buy this great album but unfortunate...    sadness\n",
       "1956983160        @Pokinatcha  in all honesty...pain   blech.    sadness\n",
       "1956983171  Ok ... the passengers ... no one is alive ... ...    sadness\n",
       "1956983690  @vincew @stefanyngo  i fell asleep on the beac...    sadness\n",
       "1956983874  So great to see Oin &amp; Cynthia.  So happy. ...  happiness\n",
       "1956985535  @havingmysay  dude, that is my favorite sandwi...  happiness\n",
       "1956985764  @RachelLock22 ohh thursday i have exams.. all ...    sadness\n",
       "1956986211  @gcrush @nopantsdance i was just thinking abou...    sadness\n",
       "1956986767  @artfuldodga I love those 'it'sakey' USB stick...    sadness\n",
       "1956989514  @sweeetnspicy hiii im on my ipod...i cant fall...    sadness\n",
       "1956989526    dont wanna work 11-830 tomorrow  but i get paid    sadness\n",
       "1956989560  feels sad coz i wasnt able to play with the gu...    sadness\n",
       "...                                                       ...        ...\n",
       "1753903325                      Had a great time last night!   happiness\n",
       "1753903509  @watermelon39 haha! And Twitter! Hard though i...    sadness\n",
       "1753903552             @HosamKamel Thanks for the follow man   happiness\n",
       "1753903798                  @dai_bach daps were the best lol   happiness\n",
       "1753903814      @DebbieFletcher haha i will remember that  xx  happiness\n",
       "1753903881  @sharlynnx ME TOO! please come online *-* hope...  happiness\n",
       "1753904142  @JamesHancox LOL or maybe it's the tooth fairy...  happiness\n",
       "1753904185  Wow! Up, coffee in hand and already outside.  ...  happiness\n",
       "1753904324  THE VIDEO IS FINALLY DONE WOOOOOOOOOOOOOOOOOOO...  happiness\n",
       "1753904357  Watched Wolverine yesterday ... a spur of the ...  happiness\n",
       "1753904398                        is heading off to the fair     sadness\n",
       "1753904399     the sunset view is SO beautiful from my room!   happiness\n",
       "1753904448  @McMedia Very well thank you! How are you, mor...  happiness\n",
       "1753904494  @muffinwomanxo EH! u dont like retro? tisk tis...  happiness\n",
       "1753904626  @acchanosaurus good luck chan! gue kmrn bawa b...  happiness\n",
       "1753904912  Sitting in Gatwick- going home for a week! can...  happiness\n",
       "1753904919           @maynaseric good luck with your auction   happiness\n",
       "1753905121  @McMedia husband is golfing &amp; the Toddler ...  happiness\n",
       "1753905153  going to watch boy in the striped pj's hope i ...  happiness\n",
       "1753918809  gave the bikes a thorough wash, degrease it an...  happiness\n",
       "1753918818  had SUCH and AMAZING time last night, McFly we...  happiness\n",
       "1753918900                     Succesfully following Tayla!!   happiness\n",
       "1753919043  @niariley WASSUP BEAUTIFUL!!! FOLLOW ME!!  PEE...  happiness\n",
       "1965997032                             Missing my baby ducks     sadness\n",
       "1694587827  Have just bought a TV tuner for my laptop.  He...  happiness\n",
       "1751358127  i now know that we've made a difference in eac...  happiness\n",
       "1695411449  @supermouse104 hey arthur! i forgot to say tha...  happiness\n",
       "1964096165  @neoknits -- That's got to be hard. My parents...    sadness\n",
       "1961440619  @herecomesdomzi and what about me, huh? I'm cr...    sadness\n",
       "1752415055  And ... Happy Mother's Day to all Moms   You s...  happiness\n",
       "\n",
       "[10362 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the sentiment data\n",
    "df = pd.DataFrame.from_csv('/home/claire/Documents/jobs/job-hunting/massively/sentiment_analysis/dfe_happysad_utf.csv', header=0, sep=',', index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split the data into test and train\n",
    "df['split'] = np.random.randn(df.shape[0], 1)\n",
    "\n",
    "msk = np.random.rand(len(df)) <= 0.7\n",
    "\n",
    "df_train = df[msk]\n",
    "df_test = df[~msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split training and testing tweets by sadnesss and happiness\n",
    "sad_train = df_train.loc[df_train['label'] == 'sadness']\n",
    "happy_train = (df_train.loc[df_train['label'] == 'happiness']).head(3612)\n",
    "\n",
    "sad_test = df_test.loc[df_test['label'] == 'sadness']\n",
    "happy_test = (df_test.loc[df_test['label'] == 'happiness']).head(1543)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1543 1543\n",
      "3612 3612\n"
     ]
    }
   ],
   "source": [
    "# create numpy arrays\n",
    "np_sad_train = sad_train.as_matrix(columns=df.columns[0:2])\n",
    "np_happy_train = happy_train.as_matrix(columns=df.columns[0:2])\n",
    "\n",
    "np_sad_test = sad_test.as_matrix(columns=df.columns[0:2])\n",
    "np_happy_test = happy_test.as_matrix(columns=df.columns[0:2])\n",
    "\n",
    "print(len(np_sad_test), len(np_happy_test))\n",
    "print(len(np_sad_train), len(np_happy_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set maximum sentence length and number of dimension for each word vector\n",
    "maxSeqLength = df_train['features'].str.len().max()\n",
    "numFiles = 10362"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "strip_special_chars = re.compile(\"[^A-Za-z0-9 ]+\")\n",
    "\n",
    "def cleanSentences(string):\n",
    "    string = string.lower().replace(\"<br />\", \" \")\n",
    "    return re.sub(strip_special_chars, \"\", string.lower())\n",
    "\n",
    "def newline(string):\n",
    "    newline_pattern = re.compile(\"[^\\n]*\\n\")\n",
    "    return re.findall(newline_pattern, string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class indexedArray(np.ndarray):\n",
    "    def __new__(cls, *args, **kwargs):\n",
    "        return np.array(*args, **kwargs).view(indexedArray)\n",
    "    def index(self, value):\n",
    "        return np.where(self==value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorize(model):\n",
    "    \n",
    "    ids = np.zeros((numFiles, maxSeqLength), dtype='int32')\n",
    "    vectors = indexedArray(model.vectors)\n",
    "    fileCounter = 0\n",
    "    \n",
    "    for tweet in np_sad_train:\n",
    "        print(tweet)\n",
    "        indexCounter = 0\n",
    "        cleaned = cleanSentences(tweet[0])\n",
    "        split = cleaned.split()\n",
    "        for word in split:\n",
    "            try:\n",
    "                index = vectors.index(model[word])\n",
    "                tuples = [x[0] for x in index]\n",
    "                ids[fileCounter][indexCounter] = tuples[0]\n",
    "                print(ids[fileCounter][indexCounter])\n",
    "            except KeyError:\n",
    "                ids[fileCounter][indexCounter] = 399999 #Vector for unknown words\n",
    "                print(ids[fileCounter][indexCounter])\n",
    "            indexCounter = indexCounter + 1\n",
    "            if indexCounter >= maxSeqLength:\n",
    "                break\n",
    "        fileCounter = fileCounter + 1\n",
    "        if fileCounter == 10:\n",
    "            break\n",
    "            \n",
    "    for tweet in np_happy_train:\n",
    "        print(tweet)\n",
    "        indexCounter = 0\n",
    "        cleaned = cleanSentences(tweet[0])\n",
    "        split = cleaned.split()\n",
    "        for word in split:\n",
    "            try:\n",
    "                index = vectors.index(model[word])\n",
    "                tuples = [x[0] for x in index]\n",
    "                ids[fileCounter][indexCounter] = tuples[0]\n",
    "                print(ids[fileCounter][indexCounter])\n",
    "            except KeyError:\n",
    "                ids[fileCounter][indexCounter] = 399999 #Vector for unknown words\n",
    "                print(ids[fileCounter][indexCounter])\n",
    "        indexCounter = indexCounter + 1\n",
    "        if indexCounter >= maxSeqLength:\n",
    "            break\n",
    "        fileCounter = fileCounter + 1\n",
    "        if fileCounter == 20:\n",
    "            break\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Layin n bed with a headache  ughhhh...waitin on your call...' 'sadness']\n",
      "399999\n",
      "157\n",
      "4916\n",
      "24\n",
      "6\n",
      "16030\n",
      "399999\n",
      "25\n",
      "772\n",
      "969\n",
      "[ \"I should be sleep, but im not! thinking about an old friend who I want. but he's married now. damn, &amp; he wants me 2! scandalous! \"\n",
      " 'sadness']\n",
      "72\n",
      "280\n",
      "32\n",
      "4488\n",
      "42\n",
      "7766\n",
      "38\n",
      "2854\n",
      "79\n",
      "31\n",
      "246\n",
      "1620\n",
      "57\n",
      "72\n",
      "2151\n",
      "42\n",
      "53181\n",
      "882\n",
      "163\n",
      "23280\n",
      "11826\n",
      "36\n",
      "6286\n",
      "746\n",
      "399999\n",
      "21936\n",
      "['@charviray Charlene my love. I miss you ' 'sadness']\n",
      "399999\n",
      "399999\n",
      "609\n",
      "611\n",
      "72\n",
      "5148\n",
      "207\n",
      "['Ugh! I have to beat this stupid song to get to the next  rude!' 'sadness']\n",
      "399999\n",
      "72\n",
      "39\n",
      "7\n",
      "3251\n",
      "33\n",
      "13147\n",
      "584\n",
      "7\n",
      "689\n",
      "7\n",
      "1\n",
      "479\n",
      "16545\n",
      "['The storm is here and the electricity is gone ' 'sadness']\n",
      "1\n",
      "3828\n",
      "11\n",
      "622\n",
      "3\n",
      "1\n",
      "2056\n",
      "11\n",
      "3113\n",
      "[ 'How are YOU convinced that I have always wanted you? What signals did I give off...damn I think I just lost another friend '\n",
      " 'sadness']\n",
      "311\n",
      "26\n",
      "207\n",
      "4767\n",
      "20\n",
      "72\n",
      "39\n",
      "522\n",
      "1783\n",
      "207\n",
      "154\n",
      "2943\n",
      "216\n",
      "72\n",
      "791\n",
      "399999\n",
      "72\n",
      "1811\n",
      "72\n",
      "325\n",
      "543\n",
      "167\n",
      "1620\n",
      "[ \"@IsaacMascote  i'm sorry people are so rude to you, isaac, they should get some manners and know better than to be so lewd!\"\n",
      " 'sadness']\n",
      "399999\n",
      "7766\n",
      "14040\n",
      "83\n",
      "26\n",
      "95\n",
      "16545\n",
      "7\n",
      "207\n",
      "3500\n",
      "47\n",
      "280\n",
      "689\n",
      "48\n",
      "12433\n",
      "3\n",
      "1006\n",
      "800\n",
      "70\n",
      "7\n",
      "32\n",
      "95\n",
      "38337\n",
      "[ \"Fudge.... Just BS'd that whole paper.... So tired.... Ugh I hate school.....  time to sleep!!!!!!!!!!!\"\n",
      " 'sadness']\n",
      "20521\n",
      "325\n",
      "6927\n",
      "20\n",
      "850\n",
      "1149\n",
      "95\n",
      "11452\n",
      "399999\n",
      "72\n",
      "5547\n",
      "302\n",
      "65\n",
      "7\n",
      "4488\n",
      "[ \"@ether_radio yeah :S i feel all funny cause i haven't slept enough  i woke my mum up cause i was singing she's not impressed :S you?\"\n",
      " 'sadness']\n",
      "399999\n",
      "18415\n",
      "15\n",
      "72\n",
      "2297\n",
      "50\n",
      "9019\n",
      "701\n",
      "72\n",
      "399999\n",
      "17470\n",
      "889\n",
      "72\n",
      "33323\n",
      "609\n",
      "38630\n",
      "98\n",
      "701\n",
      "72\n",
      "18\n",
      "3671\n",
      "399999\n",
      "38\n",
      "8349\n",
      "15\n",
      "207\n",
      "[ \"I'm having a problem with my photo here in twitter amf!!!...can't see my face! \"\n",
      " 'sadness']\n",
      "7766\n",
      "384\n",
      "6\n",
      "599\n",
      "24\n",
      "609\n",
      "3709\n",
      "622\n",
      "5\n",
      "399999\n",
      "399999\n",
      "68\n",
      "609\n",
      "1249\n",
      "[\"mmm much better day... so far! it's still quite early. last day of #uds \"\n",
      " 'happiness']\n",
      "28995\n",
      "149\n",
      "800\n",
      "137\n",
      "95\n",
      "491\n",
      "45\n",
      "191\n",
      "1087\n",
      "128\n",
      "250\n",
      "137\n",
      "2\n",
      "399999\n",
      "[ 'So great to see Oin &amp; Cynthia.  So happy.  Dinner was great, cute little place.  Too bad Oin got sick afterwards.  '\n",
      " 'happiness']\n",
      "95\n",
      "175\n",
      "7\n",
      "68\n",
      "399999\n",
      "11826\n",
      "19032\n",
      "95\n",
      "3983\n",
      "9373\n",
      "18\n",
      "175\n",
      "25638\n",
      "402\n",
      "259\n",
      "594\n",
      "1869\n",
      "399999\n",
      "1999\n",
      "6835\n",
      "3180\n",
      "[ '@havingmysay  dude, that is my favorite sandwich place ever. ummm did you take PICTURES?'\n",
      " 'happiness']\n",
      "399999\n",
      "22905\n",
      "20\n",
      "11\n",
      "609\n",
      "4582\n",
      "14074\n",
      "259\n",
      "677\n",
      "399999\n",
      "216\n",
      "207\n",
      "370\n",
      "2086\n",
      "[ 'took a math test today. The day before the test, the teacher says bring your calculator. Luke was confident. Teacher decided no calcs. '\n",
      " 'happiness']\n",
      "378\n",
      "6\n",
      "7736\n",
      "1082\n",
      "358\n",
      "1\n",
      "137\n",
      "152\n",
      "1\n",
      "1082\n",
      "1\n",
      "2703\n",
      "1591\n",
      "1917\n",
      "772\n",
      "6921\n",
      "3985\n",
      "18\n",
      "12595\n",
      "2703\n",
      "1438\n",
      "76\n",
      "399999\n",
      "[ 'omg, the concert was awesome, madrigals gave me chills on almost every piece...brooks also called up alumni, but i didnt get to go '\n",
      " 'happiness']\n",
      "69499\n",
      "1\n",
      "2719\n",
      "18\n",
      "39842\n",
      "34742\n",
      "776\n",
      "746\n",
      "21387\n",
      "25\n",
      "417\n",
      "332\n",
      "399999\n",
      "37\n",
      "89\n",
      "98\n",
      "4695\n",
      "42\n",
      "72\n",
      "399999\n",
      "689\n",
      "7\n",
      "686\n",
      "[ 'I Can`t do 30 minutes of Treadmill  but done 30 minutes for today already, gonna do 20 minutes more'\n",
      " 'happiness']\n",
      "72\n",
      "27601\n",
      "176\n",
      "399999\n",
      "1918\n",
      "2\n",
      "61017\n",
      "42\n",
      "602\n",
      "399999\n",
      "1918\n",
      "14\n",
      "358\n",
      "830\n",
      "17920\n",
      "176\n",
      "399999\n",
      "1918\n",
      "51\n",
      "[ 'I spilled my beer all over my leg. Wasted half my beer.  Home now. I met a cute girl. Good conversation.'\n",
      " 'happiness']\n",
      "72\n",
      "23453\n",
      "609\n",
      "2534\n",
      "50\n",
      "80\n",
      "609\n",
      "3650\n",
      "13918\n",
      "517\n",
      "609\n",
      "2534\n",
      "291\n",
      "163\n",
      "72\n",
      "1300\n",
      "6\n",
      "25638\n",
      "2589\n",
      "385\n",
      "6230\n",
      "['english class! working on interactive orals ' 'happiness']\n",
      "103\n",
      "477\n",
      "742\n",
      "25\n",
      "3800\n",
      "399999\n",
      "[ \"@celldweller Must... have... new music... I won't sleep until you give us Chapter 1... I might die first though...  Hurry! \"\n",
      " 'happiness']\n",
      "399999\n",
      "300\n",
      "39\n",
      "58\n",
      "166\n",
      "72\n",
      "61345\n",
      "4488\n",
      "192\n",
      "207\n",
      "791\n",
      "251\n",
      "1891\n",
      "399999\n",
      "72\n",
      "508\n",
      "1417\n",
      "46\n",
      "220\n",
      "30279\n",
      "['@PandaMayhem noooooooooooo i just look at a lot of pictures   lol lol'\n",
      " 'happiness']\n",
      "399999\n",
      "399999\n",
      "72\n",
      "325\n",
      "1406\n",
      "35\n",
      "6\n",
      "2768\n",
      "2\n",
      "2086\n",
      "39385\n",
      "39385\n"
     ]
    }
   ],
   "source": [
    "ids = vectorize(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('idsMatrix', ids)\n",
    "ids = np.load('idsMatrix.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3612 3612\n",
      "7224\n",
      "14548\n"
     ]
    }
   ],
   "source": [
    "train_arrays = ids\n",
    "train_labels = np.zeros(numFiles)\n",
    "\n",
    "# create a numpy array of 0s and 1s for neg and pos\n",
    "\n",
    "for i in range(len(np_sad_train)):\n",
    "    train_labels[i] = 0\n",
    "    train_labels[len(np_happy_train) + i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_arrays = ids\n",
    "test_labels = np.zeros(numFiles)\n",
    "\n",
    "# create a numpy array of 0s and 1s for neg and pos\n",
    "\n",
    "for i in range(len(np_sad_test)):\n",
    "    train_labels[i] = 0\n",
    "    train_labels[len(np_happy_test) + i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
